{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장의 유사도 분석\n",
    ": 두 개의 문장이 비슷한지 또는 관련이 있는지 분석\n",
    "- 레벤슈타인 거리\n",
    "- N-gram 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 레벤슈타인 거리\n",
    "- 두 개의 문자열이 어느정도 다른지 나타내는 것\n",
    "- 편집거리(Edit Distance)라고도 부른다\n",
    "- 의학 분야에서는 DNA배열의 유사도를 계산할 때도 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lvenshtein import Lvenshtein\n",
    "lv = Lvenshtein()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 가나다라와 가나바라의 거리\n",
    "print(lv.calc_distance('가나다라', '가마바라'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['신촌역', '신천역', '신천군', '마곡역', '신발']\n"
     ]
    }
   ],
   "source": [
    "# 신촌역과 가장 근접한 순서로 정렬\n",
    "samples = ['신촌역', '신천군', '신천역', '마곡역', '신발']\n",
    "samples.sort(key=lambda x: lv.calc_distance('신촌역', x)) # 최소 편집횟수로 정렬 (가장 철자를 바꾸지 않고 만들 수 있는 순)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 신촌역\n",
      "1 신천역\n",
      "2 신천군\n",
      "2 마곡역\n",
      "2 신발\n"
     ]
    }
   ],
   "source": [
    "# 신촌역과 가장 근접한 순서로 정렬2\n",
    "samples = ['신촌역', '신천군', '신천역', '마곡역', '신발']\n",
    "base = samples[0]\n",
    "r = sorted(samples, key=lambda x: lv.calc_distance(base, x))\n",
    "for x in r:\n",
    "    print(lv.calc_distance(base, x), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### N-gram 분석\n",
    "- 이웃한 N개의 문자\n",
    "- 서로 다른 2개의 문장을 N-gram으로 비교해 보면 출현하는 단어의 종류와 빈도를 확인 가능\n",
    "- 논문 도용 등 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngram import Ngram\n",
    "ngram = Ngram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '늘 ', ' 강', '강남', '남에', '에서', '서 ', ' 맛', '맛있', '있는', '는 ', ' 스', '스파', '파게', '게티', '티를', '를 ', ' 먹', '먹었', '었다', '다.']\n",
      "['강남', '남에', '에서', '서 ', ' 먹', '먹었', '었던', '던 ', ' 오', '오늘', '늘의', '의 ', ' 스', '스파', '파게', '게티', '티는', '는 ', ' 맛', '맛있', '있었', '었다', '다.']\n"
     ]
    }
   ],
   "source": [
    "# 2문장으로 나누기\n",
    "a = '오늘 강남에서 맛있는 스파게티를 먹었다.'\n",
    "b = '강남에서 먹었던 오늘의 스파게티는 맛있었다.'\n",
    "\n",
    "print(ngram.ngram(a, 2))\n",
    "print(ngram.ngram(b, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘 ', '늘 강', ' 강남', '강남에', '남에서', '에서 ', '서 맛', ' 맛있', '맛있는', '있는 ', '는 스', ' 스파', '스파게', '파게티', '게티를', '티를 ', '를 먹', ' 먹었', '먹었다', '었다.']\n",
      "['강남에', '남에서', '에서 ', '서 먹', ' 먹었', '먹었던', '었던 ', '던 오', ' 오늘', '오늘의', '늘의 ', '의 스', ' 스파', '스파게', '파게티', '게티는', '티는 ', '는 맛', ' 맛있', '맛있었', '있었다', '었다.']\n"
     ]
    }
   ],
   "source": [
    "# 3문장으로 나누기\n",
    "print(ngram.ngram(a, 3))\n",
    "print(ngram.ngram(b, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 유사도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도:  (0.7619047619047619, ['오늘', '강남', '남에', '에서', '서 ', ' 맛', '맛있', '는 ', ' 스', '스파', '파게', '게티', ' 먹', '먹었', '었다', '다.'])\n"
     ]
    }
   ],
   "source": [
    "# 2-gram\n",
    "r2 = ngram.diff_ngram(a, b, 2)\n",
    "print('유사도: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도:  (0.75, ['머신', '신러', '러닝', ' 재', '재미', '미있', '있는', '는 ', ' 기', '기술', '술이', '이라', '라 ', '공부', '부하', '고 ', ' 있', '있습', '습니', '니다', '다.'])\n"
     ]
    }
   ],
   "source": [
    "a = \"머신러닝은 매우 재미있는 기술이라 공부하고 있습니다.\"\n",
    "b = \"공부하면 재미있는 기술이라 머신러닝을 배우고 있습니다.\"\n",
    "r2 = ngram.diff_ngram(a, b, 2)\n",
    "print('유사도: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도:  (0.3699421965317919, ['빅데', '데이', '이터', ' 기', ' 기', ', ', ', ', ', ', ', ', ' 기', ' 기', '기계', '기계', '계학', '학습', ' 딥', '러닝', ', ', ', ', ', ', ', ', ' 사', ' 사', '사물', '물인', '인터', '터넷', ', ', ', ', ', ', ', ', ' 모', '모든', '든 ', ' 기', ' 기', '연결', '연결', '한다', '다.', '다.', '. ', ' 기', ' 기', ' 기', ' 기', '기계', '기계', '계가', '가 ', ' 대', '대체', '체하', ', ', ', ', ', ', ', ', ' 기', ' 기', '가 ', '을 ', '한다', '다.', '다.'])\n"
     ]
    }
   ],
   "source": [
    "a = '빅데이터를 기반으로 하여 인공지능, 기계학습과 딥 러닝 발달, 그리고 사물인터넷(IoT), 클라우드를 통해 인간뿐만 아니라 모든 기기가연결되는 초연결 시대를 의미한다. 인공지능 기술의 발달로 인해 인간의 지식 노동까지도 기계가 대체하는초지능화 시대, 홀로그램등의 기술 발달로 인한 초현실시대가 도래함을 의미한다.'\n",
    "b = '빅데이터, 기계학습, 딥러닝, 사물인터넷 등이 촉발한다. 사람을 기계가 대체하고, 모든 것이 연결된다.'\n",
    "\n",
    "r2 = ngram.diff_ngram(a, b, 2)\n",
    "print('유사도: ', r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "031516d5089d8191e78e906aaec9fc12f69b6ded71cabf4c1fff4df0e2792dca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
