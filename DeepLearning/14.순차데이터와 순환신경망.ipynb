{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순차 데이터\n",
    "- 텍스트 데이터(ex: I am a boy) : 순서가 의미가 있다.\n",
    "- 시게열 데이터(ex: 1일 10도, 2일 8도)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN (Recurrent Neural Network, 순환신경망 )\n",
    "- 순환데이터, 순환신경망 \n",
    "- 텍스트 데이터(ex: I am a boy) : 순서가 의미가 있다. \n",
    "- 시계열 데이터(ex: 1일 10도, 2일 8도)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 순환 신경망 (RNN : Recurrent Neural Network)\n",
    "- IMDB - Internet Movie Database\n",
    "- IMDB구성 : Train Data (25000개중 긍정 12500개, 부정 12500개) , Test Data (25000개중 긍정 12500개, 부정 12500개)\n",
    "- NLP : Natural Language Processing(자연어 처리)\n",
    "- 말뭉치 : 하나의 데이터셋을 말뭉치라고 표현\n",
    "- 토큰 : 하나의 단어를 토큰이라고 표현 \n",
    "- 어휘사전 : 번호로 구분된 유일한 단어들의 집단\n",
    "- 머신러닝 이나 딥러닝 에서는 데이터가 숫자로 구성되어 있어야 함으로 이런 단어들을 고유한 번호로 할당하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_input, train_target) , (test_input, test_target) = imdb.load_data(num_words= 500) # 500개 단어\n",
    "# 25000개 문장 중에서 500개 단어만 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape , test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train의 첫번째 문장의 Token 갯수\n",
    "len(train_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 샘플의 시작부분 토큰은 1을 사용한다. (1이 단어는 아니다. 시작이라는 표시)\n",
    "- 2는 선정한 단어 갯수에 포함되지 않는 단어를 표현한다.\n",
    "- train_input 자체는 numpy 배열이나 댓글에 사용된 토큰 수가 다르기 때문에 numpy 배열을 사용 못하고 python list를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# train의 target 출력\n",
    "print(train_target[:10])\n",
    "# 1 : 긍정 , 0 : 부정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련세트 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_input , val_input, train_target, val_target = train_test_split(train_input , train_target , test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.00925 178.0\n"
     ]
    }
   ],
   "source": [
    "# 각 리뷰마다 문장 길이를 시각화\n",
    "import numpy as np\n",
    "lengths = np.array([len(x) for x in train_input])\n",
    "print(np.mean(lengths) , np.median(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 오른쪽 쏠림 현상. 예상치 못하게 긴 댓글들이 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lengths)\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Padding\n",
    "- 전체 자리수를 100으로 가정했을 경우 3개 토큰만 있을 경우 나머지 97개는 비워지고 이를 0으로 채우는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_seq = pad_sequences(train_input, maxlen = 100)\n",
    "val_seq = pad_sequences(val_input, maxlen = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100)\n"
     ]
    }
   ],
   "source": [
    "# 크기 확인\n",
    "print(train_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 25000개의 훈련세트중 500개는 검증세트로 빠짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 46, 7, 14, 20, 10, 10, 470, 158]\n"
     ]
    }
   ],
   "source": [
    "# 원본의 첫번째 댓글의 마지막 10개 출력 확인\n",
    "print(train_input[0][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   1   2 195  19  49   2   2 190   4   2 352   2 183  10\n",
      "  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2\n",
      "   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2\n",
      "   2  95  14 238  56 129   2  10  10  21   2  94 364 352   2   2  11 190\n",
      "  24 484   2   7  94 205 405  10  10  87   2  34  49   2   7   2   2   2\n",
      "   2   2 290   2  46  48  64  18   4   2]\n"
     ]
    }
   ],
   "source": [
    "print(train_seq[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 순환 신경망 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.SimpleRNN(8, input_shape=(100, 500))) \n",
    "# 8: 셀 갯수\n",
    "# 500: One hot Encoding\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100, 500)\n"
     ]
    }
   ],
   "source": [
    "# one hot endocing\n",
    "train_oh = keras.utils.to_categorical(train_seq)\n",
    "print(train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding 확인하기\n",
    "print(np.sum(train_oh[0][0])) # 숫자 하나만 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 100, 500)\n"
     ]
    }
   ],
   "source": [
    "val_oh = keras.utils.to_categorical(val_seq)\n",
    "print(val_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 8)                 4072      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,081\n",
      "Trainable params: 4,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# 500 * 8 * (8 x 8) + 8 = 4072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tj/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 16s 48ms/step - loss: 0.6952 - acc: 0.5084 - val_loss: 0.6924 - val_acc: 0.5152\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.6924 - acc: 0.5172 - val_loss: 0.6917 - val_acc: 0.5188\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.6910 - acc: 0.5224 - val_loss: 0.6910 - val_acc: 0.5182\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 0.6898 - acc: 0.5332 - val_loss: 0.6902 - val_acc: 0.5274\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 0.6886 - acc: 0.5394 - val_loss: 0.6896 - val_acc: 0.5300\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 0.6874 - acc: 0.5454 - val_loss: 0.6891 - val_acc: 0.5346\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.6862 - acc: 0.5501 - val_loss: 0.6883 - val_acc: 0.5362\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.6850 - acc: 0.5549 - val_loss: 0.6878 - val_acc: 0.5402\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 0.6837 - acc: 0.5604 - val_loss: 0.6870 - val_acc: 0.5426\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 0.6825 - acc: 0.5639 - val_loss: 0.6867 - val_acc: 0.5460\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.6812 - acc: 0.5674 - val_loss: 0.6861 - val_acc: 0.5476\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 0.6799 - acc: 0.5691 - val_loss: 0.6854 - val_acc: 0.5462\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.6786 - acc: 0.5727 - val_loss: 0.6848 - val_acc: 0.5484\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.6772 - acc: 0.5748 - val_loss: 0.6842 - val_acc: 0.5490\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.6758 - acc: 0.5770 - val_loss: 0.6837 - val_acc: 0.5522\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 14s 43ms/step - loss: 0.6744 - acc: 0.5793 - val_loss: 0.6830 - val_acc: 0.5520\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.6730 - acc: 0.5830 - val_loss: 0.6824 - val_acc: 0.5530\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.6715 - acc: 0.5889 - val_loss: 0.6819 - val_acc: 0.5550\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 0.6700 - acc: 0.5929 - val_loss: 0.6812 - val_acc: 0.5582\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 16s 50ms/step - loss: 0.6684 - acc: 0.5946 - val_loss: 0.6808 - val_acc: 0.5586\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 15s 49ms/step - loss: 0.6669 - acc: 0.5986 - val_loss: 0.6804 - val_acc: 0.5600\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 0.6653 - acc: 0.6011 - val_loss: 0.6800 - val_acc: 0.5634\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 15s 48ms/step - loss: 0.6637 - acc: 0.6033 - val_loss: 0.6794 - val_acc: 0.5622\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 0.6620 - acc: 0.6060 - val_loss: 0.6787 - val_acc: 0.5618\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 15s 49ms/step - loss: 0.6604 - acc: 0.6094 - val_loss: 0.6786 - val_acc: 0.5608\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.6588 - acc: 0.6117 - val_loss: 0.6780 - val_acc: 0.5616\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.6571 - acc: 0.6130 - val_loss: 0.6775 - val_acc: 0.5628\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 16s 51ms/step - loss: 0.6554 - acc: 0.6172 - val_loss: 0.6780 - val_acc: 0.5628\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 16s 50ms/step - loss: 0.6537 - acc: 0.6186 - val_loss: 0.6771 - val_acc: 0.5642\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 16s 50ms/step - loss: 0.6521 - acc: 0.6198 - val_loss: 0.6773 - val_acc: 0.5632\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 15s 49ms/step - loss: 0.6504 - acc: 0.6224 - val_loss: 0.6773 - val_acc: 0.5644\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 15s 48ms/step - loss: 0.6487 - acc: 0.6237 - val_loss: 0.6769 - val_acc: 0.5640\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.6471 - acc: 0.6256 - val_loss: 0.6769 - val_acc: 0.5646\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 15s 49ms/step - loss: 0.6454 - acc: 0.6278 - val_loss: 0.6766 - val_acc: 0.5654\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 16s 50ms/step - loss: 0.6438 - acc: 0.6314 - val_loss: 0.6768 - val_acc: 0.5668\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 15s 49ms/step - loss: 0.6421 - acc: 0.6324 - val_loss: 0.6760 - val_acc: 0.5672\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 16s 52ms/step - loss: 0.6405 - acc: 0.6353 - val_loss: 0.6765 - val_acc: 0.5672\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 16s 51ms/step - loss: 0.6388 - acc: 0.6364 - val_loss: 0.6761 - val_acc: 0.5696\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 16s 52ms/step - loss: 0.6372 - acc: 0.6380 - val_loss: 0.6765 - val_acc: 0.5700\n"
     ]
    }
   ],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(\n",
    "  lr=1e-4, # CNN에서의 Optimizer. 0.0001로 설정함\n",
    ")\n",
    "model.compile(\n",
    "  optimizer=rmsprop, \n",
    "  loss='binary_crossentropy', # 2진분류라\n",
    "  metrics=['acc'] # 정확도\n",
    ")\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "  'data/best-simple-rnn.h5', \n",
    "  save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "  patience = 3,\n",
    "  restore_best_weights = True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "  train_oh,\n",
    "  train_target,\n",
    "  epochs=100, # RNN에서 제일 작은게 100개\n",
    "  batch_size=64, # Minibatch 사용 - 100개를 다 경사가항하면 시간이 엄청 걸림. 순환 갯수 8 * 8\n",
    "  validation_data=(val_oh, val_target),\n",
    "  callbacks=[checkpoint_cb, early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화 해보기\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 3s 16ms/step - loss: 0.6760 - acc: 0.5672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6759989857673645, 0.5672000050544739]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_oh, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## LSTM (Long Short Term Memory) 신경망 모델 구성하기\n",
    "- 순환신경망의 셀로 이전 타임스탬프의 샘플을 기억하고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 16)           8000      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 8)                 800       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,809\n",
      "Trainable params: 8,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Embedding(500, 16, input_length=100)) # 임베딩 층\n",
    "model.add(keras.layers.LSTM(8)) # LSTM 층\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) # Dense 층\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tj/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 17s 38ms/step - loss: 0.6927 - acc: 0.5221 - val_loss: 0.6922 - val_acc: 0.5428\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.6908 - acc: 0.5929 - val_loss: 0.6897 - val_acc: 0.5744\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.6862 - acc: 0.6105 - val_loss: 0.6828 - val_acc: 0.5992\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.6622 - acc: 0.6197 - val_loss: 0.6382 - val_acc: 0.6410\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.6093 - acc: 0.7279 - val_loss: 0.6028 - val_acc: 0.7402\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.5848 - acc: 0.7510 - val_loss: 0.5833 - val_acc: 0.7468\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.5665 - acc: 0.7630 - val_loss: 0.5668 - val_acc: 0.7566\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.5500 - acc: 0.7717 - val_loss: 0.5512 - val_acc: 0.7654\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.5359 - acc: 0.7781 - val_loss: 0.5399 - val_acc: 0.7682\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.5223 - acc: 0.7832 - val_loss: 0.5267 - val_acc: 0.7758\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.5102 - acc: 0.7887 - val_loss: 0.5159 - val_acc: 0.7774\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.4990 - acc: 0.7899 - val_loss: 0.5058 - val_acc: 0.7808\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.4889 - acc: 0.7920 - val_loss: 0.4968 - val_acc: 0.7838\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.4797 - acc: 0.7940 - val_loss: 0.4888 - val_acc: 0.7872\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.4711 - acc: 0.7951 - val_loss: 0.4809 - val_acc: 0.7894\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.4638 - acc: 0.7979 - val_loss: 0.4749 - val_acc: 0.7892\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.4571 - acc: 0.8004 - val_loss: 0.4702 - val_acc: 0.7920\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4512 - acc: 0.8019 - val_loss: 0.4656 - val_acc: 0.7922\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.4460 - acc: 0.8042 - val_loss: 0.4611 - val_acc: 0.7956\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4416 - acc: 0.8056 - val_loss: 0.4575 - val_acc: 0.7946\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4376 - acc: 0.8063 - val_loss: 0.4540 - val_acc: 0.7958\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.4336 - acc: 0.8097 - val_loss: 0.4531 - val_acc: 0.7908\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4309 - acc: 0.8084 - val_loss: 0.4496 - val_acc: 0.7948\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.4280 - acc: 0.8112 - val_loss: 0.4480 - val_acc: 0.7972\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.4257 - acc: 0.8108 - val_loss: 0.4467 - val_acc: 0.7986\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4234 - acc: 0.8127 - val_loss: 0.4441 - val_acc: 0.7980\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4215 - acc: 0.8138 - val_loss: 0.4456 - val_acc: 0.7970\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4200 - acc: 0.8153 - val_loss: 0.4417 - val_acc: 0.8004\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4186 - acc: 0.8139 - val_loss: 0.4404 - val_acc: 0.7998\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4170 - acc: 0.8158 - val_loss: 0.4397 - val_acc: 0.8010\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4158 - acc: 0.8174 - val_loss: 0.4403 - val_acc: 0.7992\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4151 - acc: 0.8167 - val_loss: 0.4379 - val_acc: 0.8016\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4136 - acc: 0.8160 - val_loss: 0.4386 - val_acc: 0.7986\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4130 - acc: 0.8170 - val_loss: 0.4372 - val_acc: 0.7996\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4118 - acc: 0.8180 - val_loss: 0.4362 - val_acc: 0.8020\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4112 - acc: 0.8162 - val_loss: 0.4408 - val_acc: 0.7926\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4109 - acc: 0.8172 - val_loss: 0.4361 - val_acc: 0.7994\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4101 - acc: 0.8174 - val_loss: 0.4372 - val_acc: 0.8024\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.4091 - acc: 0.8186 - val_loss: 0.4339 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4086 - acc: 0.8184 - val_loss: 0.4350 - val_acc: 0.7978\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.4080 - acc: 0.8177 - val_loss: 0.4330 - val_acc: 0.8002\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4075 - acc: 0.8178 - val_loss: 0.4345 - val_acc: 0.7986\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4068 - acc: 0.8178 - val_loss: 0.4335 - val_acc: 0.7974\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4065 - acc: 0.8184 - val_loss: 0.4322 - val_acc: 0.7982\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4061 - acc: 0.8186 - val_loss: 0.4320 - val_acc: 0.7978\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4054 - acc: 0.8178 - val_loss: 0.4320 - val_acc: 0.7982\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4047 - acc: 0.8195 - val_loss: 0.4313 - val_acc: 0.7994\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4047 - acc: 0.8191 - val_loss: 0.4319 - val_acc: 0.7992\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4044 - acc: 0.8170 - val_loss: 0.4321 - val_acc: 0.8036\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4039 - acc: 0.8187 - val_loss: 0.4305 - val_acc: 0.8004\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4033 - acc: 0.8195 - val_loss: 0.4351 - val_acc: 0.8034\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4029 - acc: 0.8180 - val_loss: 0.4316 - val_acc: 0.7990\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.4024 - acc: 0.8189 - val_loss: 0.4301 - val_acc: 0.8040\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.4018 - acc: 0.8195 - val_loss: 0.4295 - val_acc: 0.8018\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4016 - acc: 0.8181 - val_loss: 0.4296 - val_acc: 0.8026\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4013 - acc: 0.8192 - val_loss: 0.4290 - val_acc: 0.8024\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4008 - acc: 0.8195 - val_loss: 0.4311 - val_acc: 0.8074\n",
      "Epoch 58/100\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.4006 - acc: 0.8187 - val_loss: 0.4298 - val_acc: 0.7994\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.4001 - acc: 0.8182 - val_loss: 0.4283 - val_acc: 0.8014\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.3996 - acc: 0.8199 - val_loss: 0.4291 - val_acc: 0.8046\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.3993 - acc: 0.8194 - val_loss: 0.4299 - val_acc: 0.8042\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.3989 - acc: 0.8185 - val_loss: 0.4289 - val_acc: 0.8052\n"
     ]
    }
   ],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(\n",
    "  lr=1e-4, # CNN에서의 Optimizer. 0.0001로 설정함\n",
    ")\n",
    "model.compile(\n",
    "  optimizer=rmsprop, \n",
    "  loss='binary_crossentropy', # 2진분류라\n",
    "  metrics=['acc'] # 정확도\n",
    ")\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "  'data/best-simple-lstm.h5', \n",
    "  save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "  patience = 3,\n",
    "  restore_best_weights = True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "  train_seq,\n",
    "  train_target,\n",
    "  epochs=100, # RNN에서 제일 작은게 100개\n",
    "  batch_size=64, # Minibatch 사용 - 100개를 다 경사가항하면 시간이 엄청 걸림. 순환 갯수 8 * 8\n",
    "  validation_data=(val_seq, val_target),\n",
    "  callbacks=[checkpoint_cb, early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## GRU (Gated Recurrent Unit) 신경망 모델 구성하기\n",
    "- LSTM의 추상화, 간소화된 구성으로 GRU를 사용한다.\n",
    "- LSTM은 다 좋은데 문장이 길어지면 셀들이 기억하는 것이 너무 길어진다.\n",
    "- GRU는 셀이 기억하는 것을 줄여준다. - 셀들이 기억하는 갯수를 정해줌\n",
    "- 드롭아웃을 사용할 필요가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 16)           8000      \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 8)                 624       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,633\n",
      "Trainable params: 8,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Embedding(500, 16, input_length=100)) # 임베딩 층\n",
    "model.add(keras.layers.GRU(8)) \n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) # Dense 층\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(\n",
    "  lr=1e-4, # CNN에서의 Optimizer. 0.0001로 설정함\n",
    ")\n",
    "model.compile(\n",
    "  optimizer=rmsprop, \n",
    "  loss='binary_crossentropy', # 2진분류라\n",
    "  metrics=['acc'] # 정확도\n",
    ")\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "  'data/best-simple-gru.h5', \n",
    "  save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "  patience = 3,\n",
    "  restore_best_weights = True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "  train_seq,\n",
    "  train_target,\n",
    "  epochs=100, # RNN에서 제일 작은게 100개\n",
    "  batch_size=64, # Minibatch 사용 - 100개를 다 경사가항하면 시간이 엄청 걸림. 순환 갯수 8 * 8\n",
    "  validation_data=(val_seq, val_target),\n",
    "  callbacks=[checkpoint_cb, early_stopping_cb]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "031516d5089d8191e78e906aaec9fc12f69b6ded71cabf4c1fff4df0e2792dca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
